{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#preprossing a video\n",
        "in 4 step :\n",
        "1. extact frames of video\n",
        "2. preprocessing of frames\n",
        "3. convert frame to video"
      ],
      "metadata": {
        "id": "kNS7EovP0aGU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrC-zA7hzhqf"
      },
      "outputs": [],
      "source": [
        "!pip install open_cv\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import re"
      ],
      "metadata": {
        "id": "rHmzVBSgzlpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the image processing function\n",
        "def process_and_enhance_image(image_path):\n",
        "    # Read the image in grayscale\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    stretched_image = cv2.normalize(image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
        "    processed_image = stretched_image\n",
        "\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(50 , 50))\n",
        "    processed_image = clahe.apply(image)\n",
        "\n",
        "    # Apply Laplacian filter for whole picture sharpening\n",
        "    laplacian = cv2.Laplacian(processed_image, cv2.CV_64F)\n",
        "    # Convert Laplacian to the same type as processed_image\n",
        "    laplacian = np.uint8(np.absolute(laplacian))\n",
        "    sharpened_image = cv2.addWeighted(processed_image, 1.5, laplacian, -0.5, 0)\n",
        "    final_image = sharpened_image\n",
        "\n",
        "    return final_image"
      ],
      "metadata": {
        "id": "xPP8xNMcztjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def enhance_low_light_image(image_path):\n",
        "    # Read the image from the given path\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Convert the image to the LAB color space\n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2Lab)\n",
        "\n",
        "    # Split the LAB image to different channels\n",
        "    l, a, b = cv2.split(lab_image)\n",
        "\n",
        "    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) to the L-channel\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    cl = clahe.apply(l)\n",
        "\n",
        "    # Merge the CLAHE enhanced L-channel with the a and b channels\n",
        "    merged_lab = cv2.merge((cl, a, b))\n",
        "\n",
        "    # Convert the LAB image back to BGR color space\n",
        "    enhanced_image = cv2.cvtColor(merged_lab, cv2.COLOR_Lab2BGR)\n",
        "\n",
        "    # Apply Gamma Correction to reduce the darkness\n",
        "    gamma = 1.2  # Change the value to adjust brightness\n",
        "    inv_gamma = 1.0 / gamma\n",
        "    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
        "    gamma_corrected_image = cv2.LUT(enhanced_image, table)\n",
        "\n",
        "    # Apply a bilateral filter to reduce noise while keeping edges sharp\n",
        "    final_image = cv2.bilateralFilter(gamma_corrected_image, d=9, sigmaColor=75, sigmaSpace=75)\n",
        "\n",
        "    # final_image = cv2.cvtColor(final_image, cv2.COLOR_BGR2gray)\n",
        "\n",
        "    # Save the final image to the specified output path\n",
        "    cv2.imwrite('v1.jpg' , final_image)\n",
        "\n",
        "    # Read the image in grayscale\n",
        "    final_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # Apply Laplacian filter for whole picture sharpening\n",
        "    laplacian = cv2.Laplacian(final_image, cv2.CV_64F)\n",
        "    # Convert Laplacian to the same type as processed_image\n",
        "    laplacian = np.uint8(np.absolute(laplacian))\n",
        "    sharpened_image = cv2.addWeighted(final_image , 1.5, laplacian, -0.5, 0)\n",
        "    final_image = sharpened_image\n",
        "\n",
        "    return final_image"
      ],
      "metadata": {
        "id": "xV_srIF_zyg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process all images in a directory\n",
        "def process_images_in_directory(input_folder, output_folder , night_mode = False):\n",
        "    # Create output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Get all image paths from the input folder\n",
        "    image_paths = glob.glob(os.path.join(input_folder, '*.jpg'))\n",
        "\n",
        "    # Process each image\n",
        "    for image_path in image_paths:\n",
        "        # Process and enhance the image\n",
        "        if night_mode:\n",
        "            final_image = enhance_low_light_image(image_path)\n",
        "        else:\n",
        "            final_image = process_and_enhance_image(image_path)\n",
        "\n",
        "        # Save the final image\n",
        "        base_name = os.path.basename(image_path)\n",
        "        output_path = os.path.join(output_folder, f'{base_name}')\n",
        "        cv2.imwrite(output_path, final_image)\n",
        "\n",
        "    # Print the status\n",
        "    print(f\"Image {base_name} has been processed and saved as {output_path}\")"
      ],
      "metadata": {
        "id": "nM13SKEtz31A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def images_to_video(input_folder, output_video_path, fps=20):\n",
        "    # Helper function to extract frame number from filename\n",
        "    def frame_number(file_path):\n",
        "        # Extract the base name and the number from the filename\n",
        "        basename = os.path.basename(file_path)\n",
        "        number = re.search(r'\\d+', basename)\n",
        "        return int(number.group()) if number else -1\n",
        "\n",
        "    # Get all the image file paths and sort them by frame number\n",
        "    img_paths = sorted(glob.glob(f\"{input_folder}/*.jpg\"), key=frame_number)\n",
        "\n",
        "    # Read the first image to get the dimensions\n",
        "    frame = cv2.imread(img_paths[0])\n",
        "    height, width, layers = frame.shape\n",
        "\n",
        "    # Define the codec and create VideoWriter object\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or 'XVID'\n",
        "    video = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "    for img_path in img_paths:\n",
        "        frame = cv2.imread(img_path)\n",
        "        video.write(frame)  # Write out frame to video\n",
        "\n",
        "    # Release everything when job is finished\n",
        "    video.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "N5sT1AWG0A_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract frames with zero-padded filenames\n",
        "def extract_frames(video_path, output_folder):\n",
        "    # Check if output folder exists, if not, create it\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Load the video\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Get total number of frames in the video\n",
        "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Calculate the number of digits needed for zero-padding\n",
        "    padding = len(str(total_frames))\n",
        "\n",
        "    # Initialize frame count\n",
        "    count = 0\n",
        "\n",
        "    # Loop through frames\n",
        "    while video.isOpened():\n",
        "        # Read video frame\n",
        "        success, frame = video.read()\n",
        "\n",
        "        # If successful, save frame as JPEG file\n",
        "        if success:\n",
        "            # Define the filename with zero-padding\n",
        "            filename = f\"{output_folder}/frame_{'{:0{padding}d}'.format(count, padding=padding)}.jpg\"\n",
        "            # Save the frame\n",
        "            cv2.imwrite(filename, frame)\n",
        "            count += 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "        # Release the video capture object\n",
        "    video.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "NDDZnGBZ0EGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_input_path = '/content/Carsdrivingatnight_3.mp4'  # video path\n",
        "output_directory = '/content/frames'  # output directory\n",
        "extract_frames(video_input_path, output_directory)"
      ],
      "metadata": {
        "id": "yNtWsfOm0B2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_directory = '/content/frames'  # input directory path\n",
        "output_directory = '/content/processed'  # output directory path\n",
        "process_images_in_directory(input_directory, output_directory)"
      ],
      "metadata": {
        "id": "D37fFSqO0KVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_directory = '/content/processed'  #   input directory path\n",
        "output_video = '/content/output_video2.mp4'  # output video path\n",
        "images_to_video(input_directory, output_video)"
      ],
      "metadata": {
        "id": "OwOEvZY30LLc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}